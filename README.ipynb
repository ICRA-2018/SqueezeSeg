{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _SqueezeSeg_: Convolutional Neural Nets with Recurrent CRF for Real-Time Road-Object Segmentation from 3D LiDAR Point Cloud\n",
    "\n",
    "By Bichen Wu, Alvin Wan, Xiangyu Yue, Kurt Keutzer (UC Berkeley)\n",
    "\n",
    "This repository contains a tensorflow implementation of SqueezeSeg, a convolutional neural network model for LiDAR segmentation. A demonstration of SqueezeSeg can be found below:\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"https://github.com/BichenWuUCB/SqueezeSeg/raw/master/readme/pr_0005.gif\" width=\"600\" />\n",
    "</p>\n",
    "\n",
    "\n",
    "Please refer to our video for a high level introduction of this work: https://youtu.be/Xyn5Zd3lm6s. For more details, please refer to our paper: https://arxiv.org/abs/1710.07368. If you find this work useful for your research, please consider citing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@article{wu2017squeezeseg,\n",
    "    title={Squeezeseg: Convolutional neural nets with recurrent crf for real-time road-object segmentation from 3d lidar point cloud},\n",
    "    author={Wu, Bichen and Wan, Alvin and Yue, Xiangyu and Keutzer, Kurt},\n",
    "    journal={ICRA},\n",
    "    year={2018}\n",
    "}\n",
    "@inproceedings{wu2018squeezesegv2,\n",
    "    title={SqueezeSegV2: Improved Model Structure and Unsupervised Domain Adaptation for Road-Object Segmentation from a LiDAR Point Cloud},\n",
    "    author={Wu, Bichen and Zhou, Xuanyu and Zhao, Sicheng and Yue, Xiangyu and Keutzer, Kurt},\n",
    "    booktitle={ICRA},\n",
    "    year={2019},\n",
    "}\n",
    "@inproceedings{yue2018lidar,\n",
    "    title={A lidar point cloud generator: from a virtual world to autonomous driving},\n",
    "    author={Yue, Xiangyu and Wu, Bichen and Seshia, Sanjit A and Keutzer, Kurt and Sangiovanni-Vincentelli, Alberto L},\n",
    "    booktitle={ICMR},\n",
    "    pages={458--464},\n",
    "    year={2018},\n",
    "    organization={ACM}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recently open-sourced the code for SqueezeSegV2, a follow-up work to SqueezeSeg with significantly improved performance. For details, please check out: https://github.com/xuanyuzhou98/SqueezeSegV2\n",
    "\n",
    "## License\n",
    "**SqueezeSeg** is released under the BSD license (See [LICENSE](https://github.com/BichenWuUCB/SqueezeSeg/blob/master/LICENSE) for details). The **dataset** used for training, evaluation, and demostration of SqueezeSeg is modified from [KITTI](http://www.cvlibs.net/datasets/kitti/) raw dataset. For your convenience, we provide links to download the converted dataset, which is distrubited under the [Creative Commons Attribution-NonCommercial-ShareAlike 3.0 License](https://creativecommons.org/licenses/by-nc-sa/3.0/).\n",
    "\n",
    "## Installation:\n",
    "\n",
    "The instructions are tested on Ubuntu 16.04 with python 2.7 and tensorflow 1.0 with GPU support. \n",
    "- Clone the SqueezeSeg repository:\n",
    "    ```Shell\n",
    "    git clone https://github.com/BichenWuUCB/SqueezeSeg.git\n",
    "    ```\n",
    "    We name the root directory as `$SQSG_ROOT`.\n",
    "\n",
    "- Setup virtual environment:\n",
    "    1. By default we use Python2.7. Create the virtual environment\n",
    "        ```Shell\n",
    "        virtualenv env\n",
    "        ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Activate the virtual environment\n",
    "    ```Shell\n",
    "    source env/bin/activate\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use pip to install required Python packages:\n",
    "    ```Shell\n",
    "    pip install -r requirements.txt\n",
    "    ```\n",
    "\n",
    "## Demo:\n",
    "- To run the demo script:\n",
    "  ```Shell\n",
    "  cd $SQSG_ROOT/\n",
    "  python ./src/demo.py\n",
    "  ```\n",
    "  If the installation is correct, the detector should write the detection results as well as 2D label maps to `$SQSG_ROOT/data/samples_out`. Here are examples of the output label map overlaped with the projected LiDAR signal. Green masks indicate clusters corresponding to cars and blue masks indicate cyclists.\n",
    "  <p align=\"center\">\n",
    "    <img src=\"https://github.com/BichenWuUCB/SqueezeSeg/raw/master/readme/0001.gif\" width=\"600\" />\n",
    "  </p>\n",
    "\n",
    "\n",
    "## Training/Validation\n",
    "- First, download training and validation data (3.9 GB) from this [link](https://www.dropbox.com/s/pnzgcitvppmwfuf/lidar_2d.tgz?dl=0). This dataset contains LiDAR point-cloud projected to a 2D spherical surface. Refer to our paper for details of the data conversion procedure. This dataset is converted from [KITTI](http://www.cvlibs.net/datasets/kitti/) raw dataset and is distrubited under the [Creative Commons Attribution-NonCommercial-ShareAlike 3.0 License](https://creativecommons.org/licenses/by-nc-sa/3.0/).\n",
    "    ```Shell\n",
    "    cd $SQSG_ROOT/data/\n",
    "    wget https://www.dropbox.com/s/pnzgcitvppmwfuf/lidar_2d.tgz\n",
    "    tar -xzvf lidar_2d.tgz\n",
    "    rm lidar_2d.tgz\n",
    "    ```\n",
    "\n",
    "- Now we can start training by\n",
    "    ```Shell\n",
    "    cd $SQSG_ROOT/\n",
    "    ./scripts/train.sh -gpu 0 -image_set train -log_dir ./log/\n",
    "    ```\n",
    "   Training logs and model checkpoints will be saved in the log directory.\n",
    "   \n",
    "- We can launch evaluation script simutaneously with training\n",
    "    ```Shell\n",
    "    cd $SQSG_ROOT/\n",
    "    ./scripts/eval.sh -gpu 1 -image_set val -log_dir ./log/\n",
    "    ```\n",
    "    \n",
    "- We can monitor the training process using tensorboard.\n",
    "    ```Shell\n",
    "    tensorboard --logdir=$SQSG_ROOT/log/\n",
    "    ```\n",
    "    Tensorboard displays information such as training loss, evaluation accuracy, visualization of detection results in the training process, which are helpful for debugging and tunning models, as shown below:\n",
    "    ![alt text](https://github.com/BichenWuUCB/SqueezeSeg/raw/master/readme/Screen%20Shot%202018-02-17%20at%206.13.44%20PM.png)\n",
    "    ![alt text](https://github.com/BichenWuUCB/SqueezeSeg/raw/master/readme/Screen%20Shot%202018-02-17%20at%206.14.05%20PM.png)"
   ]
  }
 ],

 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
